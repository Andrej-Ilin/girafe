{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec1963ce",
   "metadata": {},
   "source": [
    "### 1. Примеры систем рекомендаций в реальных сервисах:\n",
    "\n",
    "   * Netflix — рекомендации фильмов и сериалов на основе истории просмотров пользователя.\n",
    "   * YouTube — рекомендации видео на основе истории просмотров и взаимодействия пользователя.\n",
    "   * Amazon — рекомендации товаров на основе покупок и интересов пользователя.\n",
    "   * Spotify — рекомендации музыкальных треков на основе прослушанных песен.\n",
    "   * Instagram — рекомендации постов и аккаунтов на основе взаимодействий с контентом.\n",
    "\n",
    "\n",
    "### 2. Типы откликов и их важнейшие свойства:\n",
    "\n",
    "   * Явный отклик (Explicit Feedback): Прямой отклик пользователя, например, рейтинг товара. Свойства: точный, но требует явного действия со стороны пользователя.\n",
    "   * Неявный отклик (Implicit Feedback): Косвенные данные, например, история просмотров или кликов. Свойства: легко собирается, но может быть менее точным.\n",
    "   * Положительный отклик (Positive Feedback): Отзывы, подтверждающие предпочтение, например, покупка товара.\n",
    "   * Отрицательный отклик (Negative Feedback): Отзывы, указывающие на неприязнь, например, отсутствие покупки.\n",
    "\\end{itemize}\n",
    "\n",
    "### 3. Примеры открытых наборов данных:\n",
    "\n",
    "   * MovieLens — набор данных о фильмах и оценках пользователей.\n",
    "   * Amazon Product Review Dataset — данные о продуктах и отзывах покупателей.\n",
    "   * Yelp Dataset — данные о ресторанах, отзывах и пользователях.\n",
    "\n",
    "\n",
    "### 4. Формализация задачи о дополнении матрицы (Matrix Completion):\n",
    "Задача дополнения матрицы заключается в том, чтобы восстановить недостающие значения в матрице $ R $, где строки представляют пользователей, а столбцы — товары. Задача формулируется как:\n",
    "$\n",
    "\\min_{X, Y} \\| R - X Y^T \\|_F^2 + \\lambda \\left( \\| X \\|_F^2 + \\| Y \\|_F^2 \\right)\n",
    "$\n",
    "где $ R $ — матрица откликов, $ X $ и $ Y $ — матрицы признаков для пользователей и товаров соответственно, $ \\lambda $ — коэффициент регуляризации, а $ \\| \\cdot \\|_F $ — нормировка Фробениуса.\n",
    "\n",
    "### 5. Формализация задачи ранжирования (Ranking Problem):\n",
    "Задача ранжирования заключается в том, чтобы упорядочить элементы (например, товары или документы) по релевантности. Формализуется как:\n",
    "$\n",
    "\\min_{\\theta} \\sum_{i=1}^{N} \\sum_{j=1}^{M} L(y_{ij}, \\hat{y}_{ij}(\\theta))\n",
    "$\n",
    "где $ L $ — функция потерь, $ y_{ij} $ — истинный порядок, $ \\hat{y}_{ij}(\\theta) $ — предсказанный порядок для пары объектов $ i $ и $ j $, $ \\theta $ — параметры модели.\n",
    "\n",
    "### 6. Формулы для схожести в алгоритме Collaborative Filtering:\n",
    "\n",
    "   * Косинусная схожесть:\n",
    "   $\n",
    "    \\text{sim}(A, B) = \\frac{A \\cdot B}{\\| A \\| \\| B \\|}\n",
    "   $\n",
    "   * Корреляция Пирсона:\n",
    "   $\n",
    "    \\text{sim}(A, B) = \\frac{\\sum_{i} (A_i - \\bar{A})(B_i - \\bar{B})}{\\sqrt{\\sum_{i} (A_i - \\bar{A})^2} \\sqrt{\\sum_{i} (B_i - \\bar{B})^2}}\n",
    "   $\n",
    "   * Жаккардова схожесть:\n",
    "   $\n",
    "    \\text{sim}(A, B) = \\frac{|A \\cap B|}{|A \\cup B|}\n",
    "   $\n",
    "\n",
    "\n",
    "### 7. Разница между подходами item-based и user-based в Collaborative Filtering:\n",
    "- Item-based approach: Схожесть вычисляется между объектами (например, товарами или фильмами), а не между пользователями. Рекомендуются похожие товары.\n",
    "- User-based approach: Схожесть вычисляется между пользователями, и рекомендации делаются на основе предпочтений пользователей, схожих с текущим.\n",
    "\n",
    "### 8. Формулировка алгоритма ALS (Alternating Least Squares):\n",
    "Алгоритм ALS решает задачу матричного дополнения, чередуя шаги оптимизации по пользователям и товарам:\n",
    "1. Фиксируем матрицу $ Y $ (товары) и находим $ X $ (пользователи):\n",
    "$\n",
    "X = (Y^T Y + \\lambda I)^{-1} Y^T R\n",
    "$\n",
    "2. Фиксируем матрицу $ X $ и находим $ Y $:\n",
    "$\n",
    "Y = (X^T X + \\lambda I)^{-1} X^T R\n",
    "$\n",
    "Здесь $ R $ — матрица откликов, $ \\lambda $ — регуляризация, и $ I $ — единичная матрица.\n",
    "\n",
    "### 9. Разница между явным и неявным ALS:\n",
    "- Explicit ALS: Использует явные отклики пользователей (например, оценки).\n",
    "- Implicit ALS: Использует неявные данные, такие как клики или просмотры.\n",
    "\n",
    "### 10. Подход \"two-tower\" в системах рекомендаций:\n",
    "Подход \"two-tower\" использует две нейронные сети для кодирования пользователей и товаров в независимые векторные представления, которые затем используются для предсказания релевантности. Это подходит для задач с большими объемами данных и позволяет масштабировать систему.\n",
    "\n",
    "### 11. Формула для NDCG (Normalized Discounted Cumulative Gain):\n",
    "$\n",
    "NDCG_k = \\frac{1}{Z_k} \\sum_{i=1}^{k} \\frac{2^{rel(i)} - 1}{\\log_2(i + 1)}\n",
    "$\n",
    "где $ rel(i) $ — релевантность элемента $ i $, $ Z_k $ — нормировочная константа.\n",
    "\n",
    "### 12. Формула для RankNet loss:\n",
    "$\n",
    "L = \\sum_{i,j} \\log(1 + \\exp(-y_{ij} (s_i - s_j)))\n",
    "$\n",
    "где $ y_{ij} $ — истинный порядок (1 для правильного, 0 для неправильного), а $ s_i, s_j $ — предсказания для объектов $ i $ и $ j $.\n",
    "\n",
    "### 13. Три алгоритма индексов kNN:\n",
    "\n",
    "   * Алгоритм KD-деревьев.\n",
    "   * Алгоритм Ball Tree.\n",
    "   * Алгоритм Locality Sensitive Hashing (LSH).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0b1171",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa307f9",
   "metadata": {},
   "source": [
    "Вот ответы на ваши вопросы по системам рекомендаций:\n",
    "\n",
    "### 1. Цель систем рекомендаций:\n",
    "Системы рекомендаций предназначены для фильтрации и представления пользователям релевантной информации, основанной на их предпочтениях, поведении или интересах. Основная цель таких систем — помочь пользователям находить интересные объекты (товары, фильмы, музыку и т.д.) среди огромного количества доступной информации. Они экономят время пользователей, предоставляя им персонализированные рекомендации, улучшая опыт взаимодействия с сервисами, такими как онлайн-магазины, видео- и музыкальные платформы, социальные сети и т.д.\n",
    "\n",
    "### 2. Примеры систем рекомендаций:\n",
    "\n",
    "   * Netflix: Рекомендации фильмов и сериалов на основе истории просмотров и предпочтений пользователя.\n",
    "   * YouTube: Рекомендации видео, основанные на просмотренной истории и предпочтениях пользователя.\n",
    "   * Amazon: Рекомендации товаров на основе покупок, интересов и поиска пользователей.\n",
    "   * Spotify: Рекомендации музыкальных треков на основе прослушанных песен и предпочтений пользователя.\n",
    "   * Instagram: Рекомендации аккаунтов и постов на основе активности пользователя (лайки, комментарии и подписки).\n",
    "\n",
    "\n",
    "### 3. Основные наборы данных (конкурсы), хотя бы 2:\n",
    "\n",
    "   * MovieLens: Один из самых известных наборов данных для систем рекомендаций, содержащий информацию о фильмах и оценках пользователей.\n",
    "   * Kaggle Competition - Netflix Prize: Конкурс, организованный Netflix, где участникам предоставлялись данные о рейтингах фильмов для улучшения алгоритмов рекомендаций.\n",
    "\n",
    "\n",
    "### 4. Формализация задачи для систем рекомендаций:\n",
    "\n",
    "#### a) Задача дополнения матрицы (Matrix Completion):\n",
    "Задача дополнения матрицы заключается в восстановлении недостающих значений в матрице откликов $ R $, где строки представляют пользователей, а столбцы — объекты (например, товары или фильмы). Целью является минимизация ошибки между предсказанными значениями и реальными данными:\n",
    "$\n",
    "\\min_{X, Y} \\| R - X Y^T \\|_F^2 + \\lambda \\left( \\| X \\|_F^2 + \\| Y \\|_F^2 \\right)\n",
    "$\n",
    "где $ X $ — матрица признаков пользователей, $ Y $ — матрица признаков объектов, $ \\lambda $ — коэффициент регуляризации, а $ \\| \\cdot \\|_F $ — норма Фробениуса.\n",
    "\n",
    "#### b) Задача ранжирования (Ranking Problem):\n",
    "Задача ранжирования заключается в упорядочивании объектов (например, товаров или фильмов) по их релевантности для конкретного пользователя. Формализация задачи может выглядеть следующим образом:\n",
    "$\n",
    "\\min_{\\theta} \\sum_{i=1}^{N} \\sum_{j=1}^{M} L(y_{ij}, \\hat{y}_{ij}(\\theta))\n",
    "$\n",
    "где $ L $ — функция потерь, $ y_{ij} $ — истинный порядок для объектов $ i $ и $ j $, $ \\hat{y}_{ij}(\\theta) $ — предсказанный порядок для этой пары объектов, $ \\theta $ — параметры модели.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f5d1bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22c541ea",
   "metadata": {},
   "source": [
    "### 6. **Общий конвейер для современных систем рекомендаций (Pipeline)**\n",
    "\n",
    "Современные системы рекомендаций обычно включают несколько ключевых этапов, которые обеспечивают точность и эффективность в процессе генерации рекомендаций. Эти этапы могут быть представлены через два основных компонента: **candidates funnel (фильтрация кандидатов)** и **models cascade (каскад моделей)**.\n",
    "\n",
    "#### **Candidates Funnel (Фильтрация кандидатов)**:\n",
    "На этом этапе система фильтрует объекты, которые могут быть рекомендованы пользователю, основываясь на различных факторах и фильтрах. Обычно используются такие методы, как:\n",
    "- **Коллаборативная фильтрация (Collaborative Filtering)**: Поиск объектов, которые были популярны среди пользователей с похожими предпочтениями.\n",
    "- **Контентная фильтрация (Content-Based Filtering)**: Отбор объектов, которые имеют схожие характеристики с теми, что уже были интересны пользователю.\n",
    "- **Популярность или частота использования**: Выбор наиболее популярных объектов среди всех пользователей.\n",
    "\n",
    "Этап **candidates funnel** помогает сузить количество объектов, из которых система будет выбирать те, что, вероятно, будут наиболее релевантны пользователю. Это может включать большое количество объектов, и задача состоит в том, чтобы выбрать самые подходящие для дальнейшей обработки.\n",
    "\n",
    "#### **Models Cascade (Каскад моделей)**:\n",
    "После того, как кандидаты отобраны на первом этапе, для их оценки используется более сложная обработка, основанная на моделях машинного обучения. Эти модели могут включать:\n",
    "- **Модели ранжирования**: Используют такие алгоритмы, как RankNet, LambdaMART, которые оценивают, какие объекты из выбранных кандидатов наиболее релевантны.\n",
    "- **Гибридные модели**: Комбинируют несколько методов, например, контентную и коллаборативную фильтрацию, с использованием нейронных сетей или других техник.\n",
    "- **Методы обучения с подкреплением**: Модели могут быть адаптированы на основе откликов пользователей и на основе их взаимодействий с системой.\n",
    "\n",
    "Каждый из кандидатов, отобранных на первом этапе, проходит через каскад моделей для оценки, которые дают финальные рекомендации.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. **Проблемы систем рекомендаций и их решения**\n",
    "\n",
    "#### a) **Feedback Loop (Обратная связь)**:\n",
    "Проблема обратной связи возникает, когда система рекомендаций обновляется на основе того, какие рекомендации были предложены пользователям, что в свою очередь влияет на будущие рекомендации. Это может привести к следующим эффектам:\n",
    "- **Усиление предпочтений (Filter bubble)**: Пользователи начинают получать рекомендации, которые слишком сильно соответствуют их предыдущим предпочтениям, не получая разнообразных или новых объектов.\n",
    "- **Недооценка новых объектов**: Новые товары или фильмы могут не попасть в рекомендации, поскольку система не имеет достаточного числа взаимодействий с ними.\n",
    "\n",
    "**Решения**:\n",
    "- **Регуляризация и разнообразие**: Внедрение регуляризаторов в модели рекомендаций для обеспечения разнообразия и предотвращения замкнутых циклов.\n",
    "- **Адаптивные модели**: Использование моделей, которые могут адаптироваться и учитывать не только предыдущие отклики, но и потенциал для новых предпочтений.\n",
    "- **Использование модели с \"свежими\" данными**: Включение новых элементов в рекомендации через активное включение данных о новинках или случайных рекомендациях.\n",
    "\n",
    "#### b) **Cold Start (Проблема холодного старта)**:\n",
    "Проблема холодного старта возникает, когда система рекомендаций не имеет достаточно данных для оценки предпочтений пользователя или свойств объекта. Это может происходить в нескольких случаях:\n",
    "- **Проблема холодного старта для пользователя**: Новый пользователь, который только что зарегистрировался, не имеет истории взаимодействий с системой.\n",
    "- **Проблема холодного старта для объекта**: Новый товар или фильм, для которого нет достаточного количества взаимодействий (например, просмотров или покупок).\n",
    "\n",
    "**Решения**:\n",
    "- **Использование контентной фильтрации**: Для нового пользователя можно использовать информацию о его профиле (например, пол, возраст, интересы), чтобы сделать первые рекомендации.\n",
    "- **Использование внешних источников информации**: Применение социальных сетей или внешних данных для получения информации о пользователе или объекте (например, через API или открытые данные).\n",
    "- **Использование гибридных моделей**: Комбинирование различных методов, таких как коллаборативная фильтрация и контентная фильтрация, для смягчения проблем холодного старта.\n",
    "- **Активное запрашивание откликов**: Внедрение механизма активного сбора откликов от новых пользователей (например, предложив оценить несколько товаров или фильмов при регистрации).\n",
    "\n",
    "Эти решения помогают улучшить работу системы рекомендаций, справляясь с типичными проблемами, связанными с отсутствием данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efbfe64",
   "metadata": {},
   "source": [
    "### 12. **SLIM (Sparse Linear Methods)**\n",
    "\n",
    "SLIM — это метод, используемый для рекомендательных систем, который основывается на решении задачи матричного дополнения с использованием разреженных линейных моделей. Он представляет собой подход, где система рекомендаций строится путем минимизации ошибки восстановления матрицы откликов при помощи линейных связей между товарами.\n",
    "\n",
    "#### Формализация задачи SLIM:\n",
    "Основная цель SLIM заключается в нахождении разреженной матрицы коэффициентов $W$, которая описывает связь между товарами (или пользователями). Формулировка задачи:\n",
    "$\n",
    "\\min_{W} \\| R - X W \\|_F^2 + \\lambda \\| W \\|_1\n",
    "$\n",
    "где:\n",
    "- $ R $ — исходная матрица откликов (матрица пользователей и товаров),\n",
    "- $ X $ — матрица признаков товаров,\n",
    "- $ W $ — разреженная матрица весов, показывающая схожесть между товарами,\n",
    "- $ \\| W \\|_1 $ — L1-регуляризация для обеспечения разреженности,\n",
    "- $ \\lambda $ — коэффициент регуляризации.\n",
    "\n",
    "Таким образом, SLIM использует разреженные весовые матрицы для того, чтобы получить рекомендации, минимизируя ошибку, а также избегать переобучения, контролируя разреженность матрицы.\n",
    "\n",
    "### 15. **Offline Metrics in Recommender Systems**\n",
    "\n",
    "Offline метрики — это метрики, которые используются для оценки качества работы рекомендательных систем без необходимости в реальном времени собирать данные от пользователей. Они применяются в процессе разработки и настройки модели, так как позволяют быстро и эффективно измерять качество рекомендаций до их внедрения в реальной среде.\n",
    "\n",
    "#### Основные Offline метрики:\n",
    "\n",
    "1. **Precision@k (Точность на топ-k рекомендациях)**:\n",
    "   $\n",
    "   \\text{Precision@k} = \\frac{\\text{Number of relevant items in top-k}}{k}\n",
    "   $\n",
    "   Эта метрика измеряет долю релевантных элементов в топ-k рекомендациях.\n",
    "\n",
    "2. **Recall@k (Полнота на топ-k рекомендациях)**:\n",
    "   $\n",
    "   \\text{Recall@k} = \\frac{\\text{Number of relevant items in top-k}}{\\text{Total number of relevant items}}\n",
    "   $\n",
    "   Полнота оценивает, какую долю всех релевантных объектов система включила в топ-k.\n",
    "\n",
    "3. **Mean Reciprocal Rank (MRR)**:\n",
    "   $\n",
    "   \\text{MRR} = \\frac{1}{|Q|} \\sum_{q \\in Q} \\frac{1}{\\text{rank}(q)}\n",
    "   $\n",
    "   MRR измеряет среднюю обратную позицию для правильных ответов среди всех запросов. Чем выше значение, тем лучше система.\n",
    "\n",
    "4. **Normalized Discounted Cumulative Gain (NDCG)**:\n",
    "   $\n",
    "   NDCG_k = \\frac{DCG_k}{IDCG_k}\n",
    "   $\n",
    "   DCG (Discounted Cumulative Gain) измеряет полезность элементов с учетом их позиций в списке рекомендаций, а NDCG нормирует это значение на оптимальную релевантность.\n",
    "\n",
    "5. **Mean Average Precision (MAP)**:\n",
    "   $\n",
    "   \\text{MAP} = \\frac{1}{|Q|} \\sum_{q \\in Q} \\frac{\\sum_{k=1}^{N} \\text{Precision@k}}{\\text{Number of relevant items for query q}}\n",
    "   $\n",
    "   MAP измеряет среднюю точность по всем запросам, учитывая количество релевантных элементов на разных уровнях.\n",
    "\n",
    "#### Семантика:\n",
    "- **Precision** измеряет, насколько высококачественные рекомендации предоставляются пользователю.\n",
    "- **Recall** оценивает, насколько полными являются рекомендации.\n",
    "- **MRR** оценивает, насколько быстро система находит релевантный элемент в топе рекомендаций.\n",
    "- **NDCG** учитывает не только релевантность, но и порядок элементов в рекомендациях.\n",
    "\n",
    "Эти метрики позволяют исследователям и инженерам оценить эффективность рекомендательных систем на этапе тестирования, до их внедрения в реальной работе.\n",
    "\n",
    "### 18. **ALS with MapReduce**\n",
    "\n",
    "**ALS (Alternating Least Squares)** — это популярный алгоритм для решения задачи матричного дополнения в системах рекомендаций, который использует чередование оптимизации для матриц признаков пользователей и товаров.\n",
    "\n",
    "#### Использование ALS с MapReduce:\n",
    "MapReduce — это парадигма обработки данных, которая используется для масштабируемой обработки больших объемов данных. Использование ALS в рамках MapReduce позволяет распределенно обучать модель и эффективно работать с большими данными, например, в облачных вычислениях.\n",
    "\n",
    "1. **Алгоритм ALS**:\n",
    "   В ALS задача матричного дополнения сводится к нахождению двух матриц $ X $ и $ Y $, которые минимизируют ошибку восстановления:\n",
    "   $\n",
    "   \\min_{X, Y} \\| R - X Y^T \\|_F^2 + \\lambda \\left( \\| X \\|_F^2 + \\| Y \\|_F^2 \\right)\n",
    "   $\n",
    "   где $ X $ — матрица признаков пользователей, $ Y $ — матрица признаков товаров, $ R $ — матрица откликов пользователей на товары.\n",
    "\n",
    "2. **Реализация с MapReduce**:\n",
    "   Процесс обучения ALS с использованием MapReduce включает в себя несколько этапов:\n",
    "\n",
    "   - **Map**: На этапе map для каждого пользователя и товара вычисляется ошибка матричного дополнения, а также обновляются значения для матриц $ X $ и $ Y $. Каждая пара $ (пользователь, товар) $ обрабатывается независимо.\n",
    "   \n",
    "   - **Reduce**: На этапе reduce агрегируются результаты обработки каждого пользователя и товара для вычисления обновлений для матриц $ X $ и $ Y $.\n",
    "\n",
    "   Этот подход позволяет параллельно обрабатывать большие объемы данных, что делает обучение системы масштабируемым и быстрым даже при огромных датасетах.\n",
    "\n",
    "3. **Преимущества использования MapReduce с ALS**:\n",
    "   - **Масштабируемость**: Возможность обработки огромных объемов данных, которые не помещаются в память одного узла.\n",
    "   - **Распределенная обработка**: Распараллеливание вычислений между множеством узлов ускоряет обучение модели.\n",
    "   - **Эффективность**: За счет параллельной обработки данных можно достичь хорошей производительности при больших объемах данных.\n",
    "\n",
    "Эта технология применяется в крупных системах рекомендаций, таких как Netflix, где необходимо обрабатывать данные миллионов пользователей и товаров.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ee8faa",
   "metadata": {},
   "source": [
    "### 21. **Технология Item2Item (Item-to-Item)**\n",
    "\n",
    "Технология **Item2Item (предмет к предмету)** — это широко используемый подход в рекомендательных системах, особенно для фильтрации на основе объектов. Эта технология специально разработана для того, чтобы рекомендовать объекты, схожие с теми, с которыми пользователь уже взаимодействовал, купил или высоко оценил. Основная идея **Item2Item** заключается в вычислении сходства между объектами и использовании этой информации для генерации рекомендаций.\n",
    "\n",
    "#### Ключевые компоненты технологии Item2Item:\n",
    "\n",
    "1. **Вычисление сходства между объектами:**\n",
    "   - **Косинусное сходство**: Измеряет косинус угла между двумя векторами в пространстве объектов. Объекты, которые находятся близко друг к другу с точки зрения взаимодействий пользователей (например, рейтингов или покупок), будут иметь высокое косинусное сходство.\n",
    "     $\n",
    "     \\text{cosine\\_sim}(i, j) = \\frac{\\sum_{u} R_{u,i} \\cdot R_{u,j}}{\\sqrt{\\sum_{u} R_{u,i}^2} \\cdot \\sqrt{\\sum_{u} R_{u,j}^2}}\n",
    "     $\n",
    "     где $R_{u,i}$ — рейтинг, который пользователь $u$ поставил объекту $i$, и $R_{u,j}$ — рейтинг, который пользователь $u$ поставил объекту $j$.\n",
    "     \n",
    "   - **Корреляция Пирсона**: Измеряет линейную корреляцию между рейтингами двух объектов по пользователям. Этот показатель полезен для нахождения связей между объектами, которые не очевидны в данных.\n",
    "     $\n",
    "     \\text{pearson\\_sim}(i, j) = \\frac{\\sum_{u} (R_{u,i} - \\bar{R_i})(R_{u,j} - \\bar{R_j})}{\\sqrt{\\sum_{u} (R_{u,i} - \\bar{R_i})^2} \\cdot \\sqrt{\\sum_{u} (R_{u,j} - \\bar{R_j})^2}}\n",
    "     $\n",
    "     где $\\bar{R_i}$ и $\\bar{R_j}$ — средние значения рейтингов для объектов $i$ и $j$ соответственно.\n",
    "\n",
    "   - **Сходство Жаккара**: Измеряет сходство между двумя множествами пользовательских взаимодействий. Оно часто используется при работе с бинарными данными, например, когда нужно узнать, взаимодействовал ли пользователь с объектом (кликнул, понравился и т.д.).\n",
    "     $\n",
    "     \\text{jaccard\\_sim}(i, j) = \\frac{|I_i \\cap I_j|}{|I_i \\cup I_j|}\n",
    "     $\n",
    "     где $I_i$ и $I_j$ — множества пользователей, которые взаимодействовали с объектами $i$ и $j$, соответственно.\n",
    "\n",
    "2. **Построение матрицы сходства объектов:**\n",
    "   - Первый шаг — вычисление попарных сходств между объектами. Это формирует матрицу сходства $ S $, где каждый элемент $ S(i, j) $ представляет сходство между объектами $i$ и $j$. Эта матрица может быть как плотной, так и разреженной, в зависимости от дизайна системы и количества взаимодействий между объектами и пользователями.\n",
    "\n",
    "3. **Генерация рекомендаций:**\n",
    "   - **Топ-N рекомендации**: После того как матрица сходства построена, система генерирует рекомендации, рассматривая наиболее похожие объекты на те, с которыми пользователь уже взаимодействовал. Объекты с наибольшими значениями сходства затем сортируются и рекомендуются.\n",
    "   - **Взвешенная сумма сходств**: Для каждого объекта, с которым пользователь взаимодействовал (например, поставил рейтинг или купил), система предсказывает новые объекты, вычисляя взвешенную сумму похожих объектов:\n",
    "     $\n",
    "     \\hat{R}_{u,j} = \\sum_{i \\in \\mathcal{I}_u} S(i,j) \\cdot R_{u,i}\n",
    "     $\n",
    "     где $ \\hat{R}_{u,j} $ — предсказанный рейтинг для пользователя $u$ на объект $j$, а $\\mathcal{I}_u$ — множество объектов, с которыми пользователь $u$ уже взаимодействовал.\n",
    "\n",
    "4. **Оптимизация и масштабируемость:**\n",
    "   - **Факторизация матрицы**: Для больших наборов данных матрица сходства объектов может быть вычислительно дорогой. Одним из решений является применение методов факторизации матриц (например, сингулярного разложения), чтобы уменьшить размерность данных и оптимизировать процесс рекомендаций.\n",
    "   - **Эффективная индексация**: Для повышения скорости извлечения похожих объектов можно использовать алгоритмы, такие как **k-d деревья** или **Ball Trees** для эффективного поиска ближайших соседей.\n",
    "   - **Приближенные ближайшие соседи (ANN)**: В системах, работающих с большими объемами данных, методы, такие как **Locality Sensitive Hashing (LSH)** или **Annoy**, помогают быстро находить приближенные ближайшие соседи для рекомендаций объектов.\n",
    "\n",
    "5. **Реальные приложения:**\n",
    "   - **Amazon**: Рекомендации на основе Item2Item используются в платформах электронной коммерции, таких как Amazon, для предложений продуктов, схожих с теми, которые пользователь просмотрел или купил.\n",
    "   - **Netflix**: Этот подход применяется для рекомендации фильмов и телешоу на основе сходства между объектами.\n",
    "   - **Spotify**: Музыкальные платформы часто используют рекомендации типа \"предмет к предмету\" для предложения схожих треков или альбомов на основе предпочтений пользователя.\n",
    "\n",
    "#### Преимущества технологии Item2Item:\n",
    "- **Персонализация**: Предоставляет персонализированные рекомендации на основе поведения пользователя и его взаимодействий.\n",
    "- **Масштабируемость**: Методы Item2Item хорошо масштабируются на большие наборы данных, особенно когда они комбинируются с эффективными методами индексации.\n",
    "- **Интерпретируемость**: Рекомендации, основанные на объектах, более интерпретируемы, чем некоторые модели \"черного ящика\", так как они основаны на метриках сходства, которые легко объяснить.\n",
    "\n",
    "#### Ограничения:\n",
    "- **Проблема холодного старта**: Новые объекты, не имеющие предварительных взаимодействий с пользователями, могут быть рекомендованы неэффективно.\n",
    "- **Смещение по популярности**: Популярные объекты могут доминировать в рекомендациях, что может затмить нишевые объекты.\n",
    "- **Разреженность**: В системах с большим количеством объектов и относительно меньшим количеством взаимодействий (разреженная матрица) матрицы сходства могут быть разреженными и, соответственно, менее точными.\n",
    "\n",
    "В заключение, технология **Item2Item** использует идею, что объекты, с которыми пользователи взаимодействовали схожим образом, скорее всего, будут интересны тем же пользователям. Этот метод работает путем вычисления сходства между объектами и генерации рекомендаций на основе этих сходств, и он оказался эффективным для множества платформ, использующих рекомендации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa56306",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
