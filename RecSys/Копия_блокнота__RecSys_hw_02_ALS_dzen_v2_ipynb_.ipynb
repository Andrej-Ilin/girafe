{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aaf10263",
      "metadata": {
        "id": "aaf10263"
      },
      "source": [
        "# ALS applications"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7468264",
      "metadata": {
        "id": "b7468264"
      },
      "source": [
        "## Dzen dataset\n",
        "\n",
        "Data comes from [dzen.ru](https://dzen.ru/) site and consists of likes which users put to text articles\n",
        "\n",
        "### Columns\n",
        "1. item_id - unique id of an item (article)\n",
        "2. user_id - unique id of a user\n",
        "3. source_id - unique id of an author. If two items have same source_id, then they come from one author\n",
        "4. Name of item is name of the article\n",
        "5. Raw dataset represents user_id and list of item_ids which user liked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "564cb47b-ba99-40d2-a0c4-9987cefe1253",
      "metadata": {
        "id": "564cb47b-ba99-40d2-a0c4-9987cefe1253",
        "outputId": "f606a418-ae87-4b23-9c4b-ed10ae0596b8"
      },
      "outputs": [],
      "source": [
        "# !curl -O -J -L 'https://www.dropbox.com/s/ia4bvhuqg8kesee/zen_dataset.zip?dl=1'\n",
        "# !unzip zen_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "51630f5f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T21:31:43.942096Z",
          "start_time": "2023-06-07T21:31:43.139524Z"
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T10:51:45.412325Z",
          "iopub.status.busy": "2024-03-21T10:51:45.411479Z",
          "iopub.status.idle": "2024-03-21T10:51:45.790251Z",
          "shell.execute_reply": "2024-03-21T10:51:45.789486Z",
          "shell.execute_reply.started": "2024-03-21T10:51:45.412266Z"
        },
        "id": "51630f5f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "from tqdm.notebook import tqdm\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "90965805",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T21:31:45.414950Z",
          "start_time": "2023-06-07T21:31:44.581759Z"
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T10:21:38.347864Z",
          "iopub.status.busy": "2024-03-21T10:21:38.346423Z",
          "iopub.status.idle": "2024-03-21T10:21:49.584167Z",
          "shell.execute_reply": "2024-03-21T10:21:49.583861Z",
          "shell.execute_reply.started": "2024-03-21T10:21:38.347806Z"
        },
        "id": "90965805"
      },
      "outputs": [],
      "source": [
        "item_names = pd.read_csv(\"zen_item_to_name.csv\")\n",
        "item_sources = pd.read_csv(\"zen_item_to_source.csv\")\n",
        "dataset = pd.read_csv(\"zen_ratings.csv\", converters={'item_ids': ast.literal_eval})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "772f1375",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T21:31:46.293533Z",
          "start_time": "2023-06-07T21:31:46.269174Z"
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T10:24:26.237474Z",
          "iopub.status.busy": "2024-03-21T10:24:26.236626Z",
          "iopub.status.idle": "2024-03-21T10:24:26.257193Z",
          "shell.execute_reply": "2024-03-21T10:24:26.256761Z",
          "shell.execute_reply.started": "2024-03-21T10:24:26.237441Z"
        },
        "id": "772f1375",
        "outputId": "b7166c31-72e7-48d5-e7f6-c56f4a55382e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>94962</td>\n",
              "      <td>Что обычно ожидало русских казачек в руках у к...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3972</td>\n",
              "      <td>Почему Россия решила строить новую скоростную ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>94644</td>\n",
              "      <td>5 неприличных фактов об Андрее Макаревиче, кот...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>82518</td>\n",
              "      <td>Что стало с красавицей Хмельницкой, которую му...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>53264</td>\n",
              "      <td>Понять и Простить: Почему угонщики, бежавшие и...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104498</th>\n",
              "      <td>36769</td>\n",
              "      <td>Плюс один источник мифа о рыцарях, неспособных...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104499</th>\n",
              "      <td>9190</td>\n",
              "      <td>Мой сад - малоуходный</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104500</th>\n",
              "      <td>52731</td>\n",
              "      <td>Купил первую в жизни циркулярную пилу. Честный...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104501</th>\n",
              "      <td>72660</td>\n",
              "      <td>Решили предложить Марине помощь в лечении ч.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104502</th>\n",
              "      <td>53987</td>\n",
              "      <td>Мама и сестра меня предали, я с ними не общаюсь</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>104503 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id                                               name\n",
              "0       94962  Что обычно ожидало русских казачек в руках у к...\n",
              "1        3972  Почему Россия решила строить новую скоростную ...\n",
              "2       94644  5 неприличных фактов об Андрее Макаревиче, кот...\n",
              "3       82518  Что стало с красавицей Хмельницкой, которую му...\n",
              "4       53264  Понять и Простить: Почему угонщики, бежавшие и...\n",
              "...       ...                                                ...\n",
              "104498  36769  Плюс один источник мифа о рыцарях, неспособных...\n",
              "104499   9190                              Мой сад - малоуходный\n",
              "104500  52731  Купил первую в жизни циркулярную пилу. Честный...\n",
              "104501  72660     Решили предложить Марине помощь в лечении ч.10\n",
              "104502  53987    Мама и сестра меня предали, я с ними не общаюсь\n",
              "\n",
              "[104503 rows x 2 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "item_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cb0aa9e5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T21:31:47.066054Z",
          "start_time": "2023-06-07T21:31:47.045452Z"
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T10:24:26.901979Z",
          "iopub.status.busy": "2024-03-21T10:24:26.901318Z",
          "iopub.status.idle": "2024-03-21T10:24:26.918840Z",
          "shell.execute_reply": "2024-03-21T10:24:26.917465Z",
          "shell.execute_reply.started": "2024-03-21T10:24:26.901942Z"
        },
        "id": "cb0aa9e5",
        "outputId": "33e31f58-3b31-4c6e-be22-9106cd6bfd11"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>94962</td>\n",
              "      <td>2919814402697966089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3972</td>\n",
              "      <td>3263022753228392991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>94644</td>\n",
              "      <td>-3857390427602554682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>82518</td>\n",
              "      <td>-9036908390349249792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>53264</td>\n",
              "      <td>3353856219169766284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104498</th>\n",
              "      <td>36769</td>\n",
              "      <td>3818746211375738614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104499</th>\n",
              "      <td>9190</td>\n",
              "      <td>4975535765688979937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104500</th>\n",
              "      <td>52731</td>\n",
              "      <td>3720366796439288909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104501</th>\n",
              "      <td>72660</td>\n",
              "      <td>-7860042973720636310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104502</th>\n",
              "      <td>53987</td>\n",
              "      <td>-1613465697218833842</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>104503 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id               source\n",
              "0       94962  2919814402697966089\n",
              "1        3972  3263022753228392991\n",
              "2       94644 -3857390427602554682\n",
              "3       82518 -9036908390349249792\n",
              "4       53264  3353856219169766284\n",
              "...       ...                  ...\n",
              "104498  36769  3818746211375738614\n",
              "104499   9190  4975535765688979937\n",
              "104500  52731  3720366796439288909\n",
              "104501  72660 -7860042973720636310\n",
              "104502  53987 -1613465697218833842\n",
              "\n",
              "[104503 rows x 2 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "item_sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f788e369",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T21:31:47.943529Z",
          "start_time": "2023-06-07T21:31:47.920699Z"
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T10:24:27.409874Z",
          "iopub.status.busy": "2024-03-21T10:24:27.409518Z",
          "iopub.status.idle": "2024-03-21T10:24:27.428869Z",
          "shell.execute_reply": "2024-03-21T10:24:27.428411Z",
          "shell.execute_reply.started": "2024-03-21T10:24:27.409852Z"
        },
        "id": "f788e369",
        "outputId": "267242af-b3f7-4a59-d217-e8e047d28561"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>993675863667353526</td>\n",
              "      <td>[15267, 61075, 81203, 17066, 25471, 88427, 638...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4250619547882954185</td>\n",
              "      <td>[4555, 94644, 84972, 17774, 94962, 78217, 2485...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3847785305345691076</td>\n",
              "      <td>[1898, 26703, 16525, 86939, 55017, 31069, 4035...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1785181112918558233</td>\n",
              "      <td>[75601, 102458, 28716, 100694, 5757, 47104, 60...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5078748097863903181</td>\n",
              "      <td>[72260, 40825, 2615, 42549, 379, 100818, 56827...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75905</th>\n",
              "      <td>4954138831959898373</td>\n",
              "      <td>[11881, 55520, 63054, 48015, 66952, 103830, 21...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75906</th>\n",
              "      <td>4967793435819938014</td>\n",
              "      <td>[74697, 11830, 63858, 87245, 41956, 62089, 686...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75907</th>\n",
              "      <td>7137764184903122777</td>\n",
              "      <td>[10353, 1775, 103680, 29704, 9782, 13295, 9975...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75908</th>\n",
              "      <td>2624987805086334956</td>\n",
              "      <td>[24324, 18854, 73319, 66641, 64078, 97387, 426...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75909</th>\n",
              "      <td>4022390127079841428</td>\n",
              "      <td>[64748, 64490, 99490, 80080, 8419, 84702, 7582...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75910 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   user_id                                           item_ids\n",
              "0       993675863667353526  [15267, 61075, 81203, 17066, 25471, 88427, 638...\n",
              "1      4250619547882954185  [4555, 94644, 84972, 17774, 94962, 78217, 2485...\n",
              "2      3847785305345691076  [1898, 26703, 16525, 86939, 55017, 31069, 4035...\n",
              "3      1785181112918558233  [75601, 102458, 28716, 100694, 5757, 47104, 60...\n",
              "4      5078748097863903181  [72260, 40825, 2615, 42549, 379, 100818, 56827...\n",
              "...                    ...                                                ...\n",
              "75905  4954138831959898373  [11881, 55520, 63054, 48015, 66952, 103830, 21...\n",
              "75906  4967793435819938014  [74697, 11830, 63858, 87245, 41956, 62089, 686...\n",
              "75907  7137764184903122777  [10353, 1775, 103680, 29704, 9782, 13295, 9975...\n",
              "75908  2624987805086334956  [24324, 18854, 73319, 66641, 64078, 97387, 426...\n",
              "75909  4022390127079841428  [64748, 64490, 99490, 80080, 8419, 84702, 7582...\n",
              "\n",
              "[75910 rows x 2 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e8820e36",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T21:31:55.339206Z",
          "start_time": "2023-06-07T21:31:51.973369Z"
        },
        "colab": {
          "referenced_widgets": [
            "8a5a8ae4cb8b4ea4911a57ce4a09dbb9"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T10:24:41.880387Z",
          "iopub.status.busy": "2024-03-21T10:24:41.879749Z",
          "iopub.status.idle": "2024-03-21T10:24:45.217848Z",
          "shell.execute_reply": "2024-03-21T10:24:45.217314Z",
          "shell.execute_reply.started": "2024-03-21T10:24:41.880355Z"
        },
        "id": "e8820e36",
        "outputId": "1d425f2c-550a-4dfc-95f7-615e5b4e47c5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5156d6ad94814995acfc1bbc190d18d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/75910 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "total_interactions_count = dataset.item_ids.map(len).sum()\n",
        "user_coo = np.zeros(total_interactions_count, dtype=np.int64)\n",
        "item_coo = np.zeros(total_interactions_count, dtype=np.int64)\n",
        "pos = 0\n",
        "\n",
        "for user_id, item_ids in enumerate(tqdm(dataset.item_ids)):\n",
        "    user_coo[pos : pos + len(item_ids)] = user_id\n",
        "    item_coo[pos : pos + len(item_ids)] = item_ids\n",
        "    pos += len(item_ids)\n",
        "\n",
        "shape = (max(user_coo) + 1, max(item_coo) + 1)\n",
        "user_item_matrix = sp.coo_matrix(\n",
        "    (np.ones(len(user_coo)), (user_coo, item_coo)), shape=shape\n",
        ")\n",
        "user_item_matrix = user_item_matrix.tocsr()\n",
        "sp.save_npz(\"data_train.npz\", user_item_matrix)\n",
        "# Cleanup memory. Later you need just data_train.npz\n",
        "del user_coo\n",
        "del item_coo\n",
        "del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b694e04f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T21:32:04.714869Z",
          "start_time": "2023-06-07T21:32:04.568491Z"
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T10:27:58.137388Z",
          "iopub.status.busy": "2024-03-21T10:27:58.136543Z",
          "iopub.status.idle": "2024-03-21T10:27:58.300332Z",
          "shell.execute_reply": "2024-03-21T10:27:58.299898Z",
          "shell.execute_reply.started": "2024-03-21T10:27:58.137337Z"
        },
        "id": "b694e04f"
      },
      "outputs": [],
      "source": [
        "# you could start here if you already done precomputing\n",
        "user_item_matrix = sp.load_npz(\"data_train.npz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2eacfa5e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T21:32:17.252065Z",
          "start_time": "2023-06-07T21:32:17.239886Z"
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T10:27:59.247031Z",
          "iopub.status.busy": "2024-03-21T10:27:59.246646Z",
          "iopub.status.idle": "2024-03-21T10:27:59.257786Z",
          "shell.execute_reply": "2024-03-21T10:27:59.257057Z",
          "shell.execute_reply.started": "2024-03-21T10:27:59.246994Z"
        },
        "id": "2eacfa5e",
        "outputId": "01972345-f92b-403e-9072-c9d3ecb321fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<75910x104503 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 5792423 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_item_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b7d5e4d1-cfcd-4abd-8d7e-b920bd3295b1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-21T10:38:33.146072Z",
          "iopub.status.busy": "2024-03-21T10:38:33.145637Z",
          "iopub.status.idle": "2024-03-21T10:38:33.153440Z",
          "shell.execute_reply": "2024-03-21T10:38:33.151232Z",
          "shell.execute_reply.started": "2024-03-21T10:38:33.146050Z"
        },
        "id": "b7d5e4d1-cfcd-4abd-8d7e-b920bd3295b1"
      },
      "outputs": [],
      "source": [
        "def sparce_matrix_report(matrix):\n",
        "    print('Size of raw data:', matrix.data.nbytes / 10**6, 'Mb')\n",
        "    print('Feedback matrix size:', matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d3992814-d1da-48c9-b42e-0c8b596de5ad",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-21T10:38:33.823522Z",
          "iopub.status.busy": "2024-03-21T10:38:33.822742Z",
          "iopub.status.idle": "2024-03-21T10:38:33.828502Z",
          "shell.execute_reply": "2024-03-21T10:38:33.827613Z",
          "shell.execute_reply.started": "2024-03-21T10:38:33.823495Z"
        },
        "id": "d3992814-d1da-48c9-b42e-0c8b596de5ad",
        "outputId": "b76e18d6-03c2-486a-f191-0f97f10dddd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of raw data: 46.339384 Mb\n",
            "Feedback matrix size: (75910, 104503)\n"
          ]
        }
      ],
      "source": [
        "sparce_matrix_report(user_item_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4cd37f54",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T21:32:24.023986Z",
          "start_time": "2023-06-07T21:32:23.942940Z"
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T10:38:46.019297Z",
          "iopub.status.busy": "2024-03-21T10:38:46.018979Z",
          "iopub.status.idle": "2024-03-21T10:38:46.119795Z",
          "shell.execute_reply": "2024-03-21T10:38:46.119352Z",
          "shell.execute_reply.started": "2024-03-21T10:38:46.019277Z"
        },
        "id": "4cd37f54"
      },
      "outputs": [],
      "source": [
        "item_weights = np.array(user_item_matrix.tocsc().sum(0))[0]\n",
        "top_to_bottom_order = np.argsort(-item_weights)\n",
        "item_mapping = np.empty(top_to_bottom_order.shape, dtype=int)\n",
        "item_mapping[top_to_bottom_order] = np.arange(len(top_to_bottom_order))\n",
        "total_item_count = (item_weights > 0).sum()\n",
        "total_user_count = user_item_matrix.shape[0]\n",
        "\n",
        "\n",
        "def build_debug_dataset(user_item_matrix, item_pct: float, user_pct: float):\n",
        "    '''Get given percent of top rated items and given percent of random users'''\n",
        "    user_count = int(total_user_count * user_pct),\n",
        "    item_count = int(total_item_count * item_pct)\n",
        "    item_ids = top_to_bottom_order[:item_count]\n",
        "    user_ids = np.random.choice(\n",
        "        np.arange(user_item_matrix.shape[0]), size=user_count, replace=False\n",
        "    )\n",
        "    train = user_item_matrix[user_ids]\n",
        "    train = train[:, item_ids]\n",
        "    return train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "820abbd7-d8f2-42df-aa6a-e3a6e360c94d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-07T21:32:24.803339Z",
          "start_time": "2023-06-07T21:32:24.782858Z"
        },
        "execution": {
          "iopub.execute_input": "2024-03-21T10:39:09.832524Z",
          "iopub.status.busy": "2024-03-21T10:39:09.831807Z",
          "iopub.status.idle": "2024-03-21T10:39:09.855133Z",
          "shell.execute_reply": "2024-03-21T10:39:09.854617Z",
          "shell.execute_reply.started": "2024-03-21T10:39:09.832486Z"
        },
        "id": "820abbd7-d8f2-42df-aa6a-e3a6e360c94d",
        "outputId": "058d482a-949a-4162-83c7-9d274d7f444a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of raw data: 1.076688 Mb\n",
            "Feedback matrix size: (3795, 5019)\n"
          ]
        }
      ],
      "source": [
        "debug_dataset = build_debug_dataset(user_item_matrix, 0.05, 0.05)\n",
        "\n",
        "sparce_matrix_report(debug_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f5d59e1",
      "metadata": {
        "id": "8f5d59e1"
      },
      "source": [
        "This is useful for debugging (just to save time).\n",
        "\n",
        "**Final answers should use full dataset!!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "536eb9ab",
      "metadata": {
        "id": "536eb9ab"
      },
      "source": [
        "## Split dataset matrix (5 points)\n",
        "\n",
        "in the following way: for 20% of users (random) remove one like - this will be test data. The rest is train data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95714ebd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-06T04:49:46.392558Z",
          "start_time": "2023-11-06T04:49:46.385337Z"
        },
        "id": "95714ebd"
      },
      "outputs": [],
      "source": [
        "def split_data(ratings):\n",
        "    # your code here\n",
        "    \"\"\"\n",
        "    Разделение матрицы рейтингов: для 20% пользователей удаляем один лайк\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    import scipy.sparse as sp\n",
        "    \n",
        "    # Получаем количество пользователей и выбираем 20% из них случайно\n",
        "    n_users = ratings.shape[0]\n",
        "    n_test_users = int(0.2 * n_users)data_train\n",
        "    test_user_indices = np.random.choice(n_users, n_test_users, replace=False)\n",
        "    \n",
        "    # Инициализируем тестовую матрицу\n",
        "    test_data = []\n",
        "    test_row = []\n",
        "    test_col = []\n",
        "    \n",
        "    # Создаем копию для тренировочной матрицыdata_train\n",
        "    train_matrix = ratings.copy()\n",
        "    \n",
        "    for user_idx in test_user_indices:\n",
        "        # Получаем айтемы, с которыми взаимодействовал пользователь\n",
        "        user_items = ratings.getrow(user_idx).indices\n",
        "        \n",
        "        if len(user_items) > 0:\n",
        "            # Случайно выбираем один айтем для удаления\n",
        "            item_idx = np.random.choice(user_items)\n",
        "            \n",
        "            # Добавляем в тестовую выборку\n",
        "            test_data.append(1.0)  # Бинарные взаимодействия\n",
        "            test_row.append(user_idx)\n",
        "            test_col.append(item_idx)\n",
        "            \n",
        "            # Удаляем из тренировочной выборки\n",
        "            train_matrix[user_idx, item_idx] = 0\n",
        "            data_train\n",
        "    \n",
        "    # Создаем тестовую матрицу\n",
        "    test_matrix = sp.coo_matrix((test_data, (test_row, test_col)), shape=ratings.shape)\n",
        "    test_matrix = test_matrix.tocsr()\n",
        "    \n",
        "    # Убеждаемся, что тренировочная матрица в формате CSR\n",
        "    train_matrix = train_matrix.tocsr()\n",
        "    train_matrix.eliminate_zeros()  # Удаляем нулевые элементы\n",
        "    \n",
        "    return train_matrix, test_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e7bbfe9c",
      "metadata": {
        "id": "e7bbfe9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(778, 2)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ratings, test_ratings = split_data(user_item_matrix[:10])\n",
        "train_ratings.size, test_ratings.size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8ed4c71-6501-4d34-951b-faf6fd4ce897",
      "metadata": {
        "id": "e8ed4c71-6501-4d34-951b-faf6fd4ce897"
      },
      "source": [
        "## Implement IALS (10 points each)\n",
        "\n",
        "Note that due to size of data you need to implement algorithm with _sparce matrices_!\n",
        "\n",
        "You are welcome to use classes like on the seminar:)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a751bd1",
      "metadata": {
        "id": "8a751bd1"
      },
      "outputs": [],
      "source": [
        "def ials(ratings, k=40, lam=0.1, n_iterations=10, alpha=40):\n",
        "    '''Implicit Alternating Least Squares algorithm\n",
        "\n",
        "    Args:\n",
        "        ratings: sparse matrix of ratings\n",
        "        k: size of embeddings\n",
        "        lam: regularization term\n",
        "        n_iterations: number of iterations\n",
        "        alpha: confidence scaling parameter\n",
        "\n",
        "    Returns:\n",
        "        two matrices: of user embeddings and of item embeddings\n",
        "    '''\n",
        "    import numpy as np\n",
        "    import scipy.sparse as sp\n",
        "    from tqdm.notebook import tqdm\n",
        "    \n",
        "    # Get dimensions\n",
        "    num_users, num_items = ratings.shape\n",
        "    \n",
        "    # Initialize factor matrices randomly\n",
        "    user_embeddings = np.random.normal(0, 0.01, (num_users, k))data_train\n",
        "    item_embeddings = np.random.normal(0, 0.01, (num_items, k))\n",
        "    \n",
        "    # Ensure we have CSR format for efficient row slicing\n",
        "    ratings_csr = ratings.tocsr()\n",
        "    \n",
        "    # For CSC format (efficient column access)\n",
        "    ratings_csc = ratings.tocsc()\n",
        "    \n",
        "    # Identity matrix for regularization\n",
        "    lambda_I = lam * np.eye(k)\n",
        "    \n",
        "    for _ in tqdm(range(n_iterations), desc=\"IALS iterations\"):\n",
        "        # Step 1: Fix item factors and solve for user factors\n",
        "        \n",
        "        # Precompute YtY once for all users\n",
        "        YtY = item_embeddings.T @ item_embeddings\n",
        "        \n",
        "        for u in range(num_users):\n",
        "            # Get items rated by user u\n",
        "            items = ratings_csr[u].indices\n",
        "            \n",
        "            if len(items) == 0:\n",
        "                continue\n",
        "                \n",
        "            # Get item factors for these items\n",
        "            factors = item_embeddings[items]\n",
        "            \n",
        "            # Create confidence matrix Cu and preference matrix Pu\n",
        "            # For implicit feedback: Cu = 1 + alpha*Pu, where Pu is binary\n",
        "            confidence = 1.0 + alpha\n",
        "            \n",
        "            # Compute the left side of the equation: YtCuY + λI\n",
        "            A = YtY + factors.T @ ((confidence - 1.0) * factors) + lambda_I\n",
        "            \n",
        "            # Compute the right side: YtCupu (where pu is a vector of 1's for implicit data)\n",
        "            b = confidence * (factors.sum(axis=0))\n",
        "            \n",
        "            # Solve the linear system (A * x = b)\n",
        "            try:\n",
        "                user_embeddings[u] = np.linalg.solve(A, b)\n",
        "            except np.linalg.LinAlgError:\n",
        "                # Fallback to least squares if matrix is singular\n",
        "                user_embeddings[u] = np.linalg.lstsq(A, b, rcond=None)[0]data_train\n",
        "        \n",
        "        # Step 2: Fix user factors and solve for item factors\n",
        "        \n",
        "        # Precompute XtX once for all items\n",
        "        XtX = user_embeddings.T @ user_embeddings\n",
        "        \n",
        "        for i in range(num_items):\n",
        "            # Get users who rated item i\n",
        "            users = ratings_csc[:, i].indices\n",
        "            \n",
        "            if len(users) == 0:\n",
        "                continue\n",
        "                \n",
        "            # Get user factors for these users\n",
        "            factors = user_embeddings[users]\n",
        "            \n",
        "            # Create confidence matrix Ci and preference matrix Pi\n",
        "            confidence = 1.0 + alpha\n",
        "            \n",
        "            # Compute the left side: XtCiX + λI\n",
        "            A = XtX + factors.T @ ((confidence - 1.0) * factors) + lambda_I\n",
        "            \n",
        "            # Compute the right side: XtCipi\n",
        "            b = confidence * (factors.sum(axis=0))\n",
        "            \n",
        "            # Solve the linear system\n",
        "            try:\n",
        "                item_embeddings[i] = np.linalg.solve(A, b)\n",
        "            except np.linalg.LinAlgError:\n",
        "                # Fallback to least squares if matrix is singular\n",
        "                item_embeddings[i] = np.linalg.lstsq(A, b, rcond=None)[0]\n",
        "    \n",
        "    return user_embeddings, item_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9da7c27c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<10x104503 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 778 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1bae6e13",
      "metadata": {},
      "outputs": [],
      "source": [
        "# user_embeddings, item_embeddings = ials(train_ratings, k=40, lam=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce1d293f",
      "metadata": {
        "id": "ce1d293f"
      },
      "source": [
        "## Compute MRR@100 metric for test users\n",
        "\n",
        "For ALS and IALS algorithms.\n",
        "\n",
        "**Don't forget to use full dataset!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef8cdb0d",
      "metadata": {
        "id": "ef8cdb0d"
      },
      "outputs": [],
      "source": [
        "def mrr(user_embeddings, item_embeddings, test_ratings, train_ratings, k=100):\n",
        "    \"\"\"Compute MRR@k for test ratings based on embeddings\n",
        "    \n",
        "    Args:\n",
        "        user_embeddings: matrix of user embeddings\n",
        "        item_embeddings: matrix of item embeddings\n",
        "        test_ratings: sparse matrix of test ratings\n",
        "        train_ratings: sparse matrix of train ratings\n",
        "        k: cutoff for top-k recommendations\n",
        "        \n",
        "    Returns:\n",
        "        mrr_value: Mean Reciprocal Rank score\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    \n",
        "    # Ensure test ratings is in CSR format\n",
        "    test_ratings_csr = test_ratings.tocsr()\n",
        "    train_ratings_csr = train_ratings.tocsr()\n",
        "    \n",
        "    # Get users with test items\n",
        "    test_users = np.unique(test_ratings_csr.nonzero()[0])\n",
        "    \n",
        "    # Initialize sum of reciprocal ranks\n",
        "    rr_sum = 0.0\n",
        "    count = 0\n",
        "    \n",
        "    for user in test_users:\n",
        "        # Get test items for this user\n",
        "        test_items = test_ratings_csr[user].indices\n",
        "        \n",
        "        if len(test_items) == 0:\n",
        "            continue\n",
        "            \n",
        "        # Get items this user has already rated (to exclude from recommendations)\n",
        "        train_items = train_ratings_csr[user].indices\n",
        "        \n",
        "        # Compute scores for all items\n",
        "        scores = user_embeddings[user] @ item_embeddings.T\n",
        "        \n",
        "        # Mask out training items\n",
        "        scores[train_items] = -np.inf\n",
        "        \n",
        "        # Get top-k item indices\n",
        "        top_items = np.argsort(-scores)[:k]\n",
        "        \n",
        "        # Compute reciprocal rank for each test item\n",
        "        for test_item in test_items:\n",
        "            # Find position of test item in top-k list (if present)\n",
        "            rank_idx = np.where(top_items == test_item)[0]\n",
        "            \n",
        "            if len(rank_idx) > 0:\n",
        "                # Add 1 because rank starts from 0\n",
        "                rank = rank_idx[0] + 1\n",
        "                rr_sum += 1.0 / rank\n",
        "                count += 1\n",
        "    \n",
        "    # Compute mean\n",
        "    if count > 0:\n",
        "        mrr_value = rr_sum / count\n",
        "    else:\n",
        "        mrr_value = 0.0\n",
        "        \n",
        "    return mrr_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "aa82ca33",
      "metadata": {
        "id": "aa82ca33"
      },
      "outputs": [],
      "source": [
        "# mrr_ials = mrr(ials_predictions, test_ratings, k=100)\n",
        "# print(mrr_ials)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ec74ade",
      "metadata": {
        "id": "0ec74ade"
      },
      "source": [
        "## Adjust hyperparameters of IALS to maximize MRR (10 points)\n",
        "\n",
        "Main hyperparameters are regularization and weights for implicit case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d5558e37",
      "metadata": {
        "id": "d5558e37"
      },
      "outputs": [],
      "source": [
        "def tune_ials_hyperparameters(train_ratings, test_ratings):\n",
        "    \"\"\"Tune hyperparameters for IALS to maximize MRR\n",
        "    \n",
        "    Args:\n",
        "        train_ratings: training data\n",
        "        test_ratings: test data\n",
        "        \n",
        "    Returns:\n",
        "        best_params: dictionary of best parameters\n",
        "        best_mrr: best MRR score achieved\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    from itertools import product\n",
        "    from tqdm.notebook import tqdm\n",
        "    \n",
        "    # Define hyperparameter grids\n",
        "    k_values = [20, 40, 60]  # Embedding sizes\n",
        "    lam_values = [0.01, 0.1, 1.0]  # Regularization terms\n",
        "    alpha_values = [10, 40, 100]  # Confidence scaling factors\n",
        "    \n",
        "    # Use fewer iterations for tuning to save time\n",
        "    n_iterations = 5\n",
        "    \n",
        "    # Initialize best values\n",
        "    best_mrr = 0\n",
        "    best_params = {}\n",
        "    \n",
        "    # Generate all parameter combinations\n",
        "    param_grid = list(product(k_values, lam_values, alpha_values))\n",
        "    \n",
        "    print(f\"Tuning IALS with {len(param_grid)} parameter combinations...\")\n",
        "    \n",
        "    # Track results for all combinations\n",
        "    results = []\n",
        "    \n",
        "    for k, lam, alpha in tqdm(param_grid, desc=\"Parameter Combinations\"):\n",
        "        print(f\"\\\n",
        "Testing: k={k}, λ={lam}, α={alpha}\")\n",
        "        \n",
        "        # Train IALS model with these parameters\n",
        "        user_embeddings, item_embeddings = ials(\n",
        "            train_ratings, k=k, lam=lam, alpha=alpha, n_iterations=n_iterations\n",
        "        )\n",
        "        \n",
        "        # Calculate MRR score\n",
        "        mrr_score = mrr(user_embeddings, item_embeddings, test_ratings, train_ratings)\n",
        "        \n",
        "        print(f\"MRR@100: {mrr_score:.4f}\")\n",
        "        \n",
        "        # Store result\n",
        "        results.append((k, lam, alpha, mrr_score))\n",
        "        \n",
        "        # Update best parameters if better MRR found\n",
        "        if mrr_score > best_mrr:\n",
        "            best_mrr = mrr_score\n",
        "            best_params = {'k': k, 'lam': lam, 'alpha': alpha}\n",
        "    \n",
        "    # Sort results by MRR for reporting\n",
        "    results.sort(key=lambda x: x[3], reverse=True)\n",
        "    \n",
        "    print(\"\\\n",
        "All Results (sorted by MRR):\")\n",
        "    for k, lam, alpha, score in results:\n",
        "        print(f\"k={k}, λ={lam}, α={alpha}: MRR={score:.4f}\")\n",
        "    \n",
        "    print(f\"\\\n",
        "Best Parameters: k={best_params['k']}, λ={best_params['lam']}, α={best_params['alpha']}\")\n",
        "    print(f\"Best MRR: {best_mrr:.4f}\")\n",
        "    \n",
        "    return best_params, best_mrr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ea3d1c3",
      "metadata": {
        "id": "9ea3d1c3"
      },
      "source": [
        "\n",
        "Optimal parameters of IALS are:\n",
        "\n",
        "...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "08cabf5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# best_params = tune_ials_hyperparameters(train_ratings, test_ratings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b1bfd4f",
      "metadata": {
        "id": "4b1bfd4f"
      },
      "source": [
        "## Get similarities from item2item CF (10 points)\n",
        "\n",
        "Item2item can be taken from the first homework, SLIM was implemented in the class.\n",
        "\n",
        "Alternatively you could use libraries, but in this case you will need to convert dataset to their format.\n",
        "\n",
        "You need to compute only item similarities, not predictions for users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "3a5712da",
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_i2i_similarities(ratings, method='cosine', min_common=5):\n",
        "    \"\"\"Compute item-item similarities using different methods\n",
        "    \n",
        "    Args:\n",
        "        ratings: sparse matrix of user-item interactions\n",
        "        method: similarity method ('cosine', 'pearson', or 'jaccard')\n",
        "        min_common: minimum number of users in common\n",
        "        \n",
        "    Returns:\n",
        "        similarities: item-item similarity matrix\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    import scipy.sparse as sp\n",
        "    from tqdm.notebook import tqdm\n",
        "    \n",
        "    # Ensure we have CSR format for the item-user matrix\n",
        "    item_user = ratings.T.tocsr()  # Transpose to get item-user matrix\n",
        "    \n",
        "    num_items = ratings.shape[1]\n",
        "    \n",
        "    # Initialize similarity matrix (sparse)\n",
        "    similarities = sp.lil_matrix((num_items, num_items))\n",
        "    \n",
        "    # Compute item norms for cosine similarity\n",
        "    if method == 'cosine':\n",
        "        # Compute L2 norm for each item vector\n",
        "        item_norms = np.sqrt(np.array(item_user.power(2).sum(axis=1)).flatten())\n",
        "    \n",
        "    # Iterate through items and compute similarities\n",
        "    for i in tqdm(range(num_items), desc=f\"Computing {method} similarities\"):\n",
        "        # Skip if item i has no ratings\n",
        "        if item_user[i].nnz == 0:\n",
        "            continue\n",
        "            \n",
        "        # Get users who rated item i\n",
        "        i_users = item_user[i].indices\n",
        "        \n",
        "        # We only need to compute similarities for j > i (symmetric matrix)\n",
        "        for j in range(i+1, num_items):\n",
        "            # Skip if item j has no ratings\n",
        "            if item_user[j].nnz == 0:\n",
        "                continue\n",
        "                \n",
        "            # Get users who rated item j\n",
        "            j_users = item_user[j].indices\n",
        "            \n",
        "            # Find common users who rated both items\n",
        "            common_users = np.intersect1d(i_users, j_users, assume_unique=True)\n",
        "            \n",
        "            # Skip if not enough common users\n",
        "            if len(common_users) < min_common:\n",
        "                continue\n",
        "            \n",
        "            # Compute similarity based on method\n",
        "            if method == 'cosine':\n",
        "                # Get ratings for common users\n",
        "                i_data = item_user[i, common_users].toarray().flatten()\n",
        "                j_data = item_user[j, common_users].toarray().flatten()\n",
        "                \n",
        "                # Compute cosine similarity: dot(i,j) / (norm(i) * norm(j))\n",
        "                dot_product = np.dot(i_data, j_data)\n",
        "                similarity = dot_product / (item_norms[i] * item_norms[j])\n",
        "                \n",
        "            elif method == 'jaccard':\n",
        "                # Jaccard similarity = |intersection| / |union|\n",
        "                similarity = len(common_users) / (len(i_users) + len(j_users) - len(common_users))\n",
        "                \n",
        "            elif method == 'pearson':\n",
        "                # Get ratings for common users\n",
        "                i_data = item_user[i, common_users].toarray().flatten()\n",
        "                j_data = item_user[j, common_users].toarray().flatten()\n",
        "                \n",
        "                # Compute means\n",
        "                i_mean = np.mean(i_data)\n",
        "                j_mean = np.mean(j_data)\n",
        "                \n",
        "                # Centered vectors\n",
        "                i_centered = i_data - i_mean\n",
        "                j_centered = j_data - j_mean\n",
        "                \n",
        "                # Compute numerator and denominator\n",
        "                numerator = np.dot(i_centered, j_centered)\n",
        "                denominator = np.sqrt(np.dot(i_centered, i_centered) * np.dot(j_centered, j_centered))\n",
        "                \n",
        "                # Handle division by zero\n",
        "                if denominator == 0:\n",
        "                    similarity = 0\n",
        "                else:\n",
        "                    similarity = numerator / denominator\n",
        "            \n",
        "            # Store similarity value (symmetric)\n",
        "            similarities[i, j] = similarity\n",
        "            similarities[j, i] = similarity\n",
        "    \n",
        "    # Convert to CSR format for efficient operations\n",
        "    return similarities.tocsr()\n",
        "\n",
        "\n",
        "def get_ials_similarities(item_embeddings):\n",
        "    \"\"\"Compute item-item similarities from IALS embeddings\n",
        "    \n",
        "    Args:\n",
        "        item_embeddings: Matrix of item embeddings from IALS\n",
        "        \n",
        "    Returns:\n",
        "        similarities: Item-item similarity matrix\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "    \n",
        "    # Compute cosine similarities between item embeddings\n",
        "    similarities = cosine_similarity(item_embeddings)\n",
        "    \n",
        "    # Set diagonal to zero (self-similarity)\n",
        "    np.fill_diagonal(similarities, 0)\n",
        "    \n",
        "    return similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "33435a61",
      "metadata": {
        "id": "33435a61"
      },
      "outputs": [],
      "source": [
        "# i2i_similarities = ... # your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d6b19e8",
      "metadata": {
        "id": "2d6b19e8"
      },
      "source": [
        "## Compare similarities from four algorithms (20 points)\n",
        "\n",
        "* plot distributions\n",
        "* compute metrics (which you think are relevant)\n",
        "* look at several top similar lists\n",
        "\n",
        "Make conclusion how these methods differ in computing similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "4a7d9d8d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-06T05:10:53.235810Z",
          "start_time": "2023-11-06T05:10:53.229989Z"
        },
        "id": "4a7d9d8d"
      },
      "outputs": [],
      "source": [
        "def compare_similarities(similarities_list, method_names, item_names=None, sample_size=5):\n",
        "    \"\"\"Compare similarities from different methods\n",
        "    \n",
        "    Args:\n",
        "        similarities_list: list of similarity matrices\n",
        "        method_names: list of method names\n",
        "        item_names: DataFrame mapping item IDs to names (optional)\n",
        "        sample_size: number of items to sample for comparison\n",
        "        \n",
        "    Returns:\n",
        "        None (displays plots and prints statistics)\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import scipy.sparse as sp\n",
        "    \n",
        "    n_methods = len(similarities_list)\n",
        "    \n",
        "    # 1. Plot similarity distributions\n",
        "    plt.figure(figsize=(n_methods*5, 5))\n",
        "    \n",
        "    for i, (sim_matrix, method) in enumerate(zip(similarities_list, method_names)):\n",
        "        plt.subplot(1, n_methods, i+1)\n",
        "        \n",
        "        # Get similarity values, handling both sparse and dense matrices\n",
        "        if sp.issparse(sim_matrix):\n",
        "            # For sparse matrix, use the data array\n",
        "            sim_values = sim_matrix.data\n",
        "        else:\n",
        "            # For dense matrix, flatten and remove diagonal\n",
        "            mask = ~np.eye(sim_matrix.shape[0], dtype=bool)\n",
        "            sim_values = sim_matrix[mask]\n",
        "        \n",
        "        # Plot distribution\n",
        "        sns.histplot(sim_values, kde=True)\n",
        "        plt.title(f\"{method} Similarity Distribution\")\n",
        "        plt.xlabel(\"Similarity Value\")\n",
        "        plt.ylabel(\"Frequency\")\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # 2. Compute and print basic statistics\n",
        "    print(\"Similarity Statistics:\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    for method, sim_matrix in zip(method_names, similarities_list):\n",
        "        # Get similarity values\n",
        "        if sp.issparse(sim_matrix):\n",
        "            sim_values = sim_matrix.data\n",
        "            density = sim_matrix.nnz / (sim_matrix.shape[0] * sim_matrix.shape[1])\n",
        "        else:\n",
        "            mask = ~np.eye(sim_matrix.shape[0], dtype=bool)\n",
        "            sim_values = sim_matrix[mask]\n",
        "            density = np.count_nonzero(sim_values) / len(sim_values)\n",
        "        \n",
        "        # Compute statistics\n",
        "        print(f\"{method}:\")\n",
        "        print(f\"  Mean: {np.mean(sim_values):.4f}\")\n",
        "        print(f\"  Median: {np.median(sim_values):.4f}\")\n",
        "        print(f\"  Min: {np.min(sim_values):.4f}\")\n",
        "        print(f\"  Max: {np.max(sim_values):.4f}\")\n",
        "        print(f\"  Standard Deviation: {np.std(sim_values):.4f}\")\n",
        "        print(f\"  Density: {density:.4f}\")\n",
        "        print()\n",
        "    \n",
        "    # 3. Compare top similar items for sample items\n",
        "    print(\"\\\n",
        "Top Similar Items Comparison:\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # Sample random items\n",
        "    n_items = similarities_list[0].shape[0]\n",
        "    sampled_items = np.random.choice(range(n_items), min(sample_size, n_items), replace=False)\n",
        "    \n",
        "    for item_id in sampled_items:\n",
        "        print(f\"\\\n",
        "Item {item_id}\")\n",
        "        \n",
        "        # Print item name if available\n",
        "        if item_names is not None:\n",
        "            item_name = item_names.loc[item_names['id'] == item_id, 'name'].values\n",
        "            if len(item_name) > 0:\n",
        "                print(f\"Name: {item_name[0]}\")\n",
        "        \n",
        "        # Compare top similar items from each method\n",
        "        for method, sim_matrix in zip(method_names, similarities_list):\n",
        "            # Get similarity row for this item\n",
        "            if sp.issparse(sim_matrix):\n",
        "                sim_row = sim_matrix[item_id].toarray().flatten()\n",
        "            else:\n",
        "                sim_row = sim_matrix[item_id].copy()\n",
        "            \n",
        "            # Set self-similarity to -inf to exclude from top items\n",
        "            sim_row[item_id] = -np.inf\n",
        "            \n",
        "            # Get top 5 similar items\n",
        "            top_indices = np.argsort(-sim_row)[:5]\n",
        "            top_similarities = sim_row[top_indices]\n",
        "            \n",
        "            # Print top similar items\n",
        "            print(f\"\\\n",
        "{method} Top 5 Similar Items:\")\n",
        "            for idx, (similar_item, sim) in enumerate(zip(top_indices, top_similarities)):\n",
        "                output = f\"  {idx+1}. Item {similar_item} (sim={sim:.4f})\"\n",
        "                \n",
        "                # Add item name if available\n",
        "                if item_names is not None:\n",
        "                    similar_name = item_names.loc[item_names['id'] == similar_item, 'name'].values\n",
        "                    if len(similar_name) > 0:\n",
        "                        output += f\": {similar_name[0]}\"\n",
        "                        \n",
        "                print(output)\n",
        "    \n",
        "    # 4. Compute agreement between methods\n",
        "    print(\"\\\n",
        "Agreement Between Methods:\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # Initialize agreement matrix\n",
        "    agreement_matrix = np.zeros((n_methods, n_methods))\n",
        "    \n",
        "    for i in range(n_methods):\n",
        "        for j in range(n_methods):\n",
        "            if i == j:\n",
        "                agreement_matrix[i, j] = 1.0\n",
        "                continue\n",
        "            \n",
        "            # Get similarity values for both methods\n",
        "            if sp.issparse(similarities_list[i]):\n",
        "                sim_i = similarities_list[i].toarray().flatten()\n",
        "            else:\n",
        "                sim_i = similarities_list[i].flatten()\n",
        "                \n",
        "            if sp.issparse(similarities_list[j]):\n",
        "                sim_j = similarities_list[j].toarray().flatten()\n",
        "            else:\n",
        "                sim_j = similarities_list[j].flatten()\n",
        "            \n",
        "            # Compute correlation for non-zero values\n",
        "            mask = (sim_i != 0) & (sim_j != 0)\n",
        "            if np.sum(mask) > 0:\n",
        "                agreement_matrix[i, j] = np.corrcoef(sim_i[mask], sim_j[mask])[0, 1]\n",
        "    \n",
        "    # Plot agreement matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(agreement_matrix, annot=True, fmt=\".2f\", cmap=\"YlGnBu\",\n",
        "               xticklabels=method_names, yticklabels=method_names)\n",
        "    plt.title(\"Correlation Between Similarity Methods\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7808a9b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training matrix: (75910, 104503), nnz: 5777242\n",
            "Test matrix: (75910, 104503), nnz: 15181\n",
            "Training IALS model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efdf3c0ee8d842bc9ffb423a143903ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "IALS iterations:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User embeddings shape: (75910, 40)\n",
            "Item embeddings shape: (104503, 40)\n",
            "Computing MRR@100...\n",
            "MRR@100: 0.0932\n",
            "Training IALS with optimal parameters (k=40, λ=0.1, α=40)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e97e30b9cf5d4c7b8701026032c6d94a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "IALS iterations:   0%|          | 0/15 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal MRR@100: 0.0944\n",
            "Computing item similarities...\n",
            "- Computing I2I Cosine similarity...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b395e9323c04ab1b1a0e7ba7f38c98d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Computing cosine similarities:   0%|          | 0/104503 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# 1. Split the dataset\n",
        "train_ratings, test_ratings = split_data(user_item_matrix)\n",
        "print(f\"Training matrix: {train_ratings.shape}, nnz: {train_ratings.nnz}\")\n",
        "print(f\"Test matrix: {test_ratings.shape}, nnz: {test_ratings.nnz}\")\n",
        "\n",
        "# 2. Train IALS model\n",
        "print(\"\\\n",
        "Training IALS model...\")\n",
        "user_embeddings, item_embeddings = ials(train_ratings, k=40, lam=0.1, n_iterations=10, alpha=40)\n",
        "print(f\"User embeddings shape: {user_embeddings.shape}\")\n",
        "print(f\"Item embeddings shape: {item_embeddings.shape}\")\n",
        "\n",
        "# 3. Compute MRR\n",
        "print(\"\\\n",
        "Computing MRR@100...\")\n",
        "mrr_score = mrr(user_embeddings, item_embeddings, test_ratings, train_ratings, k=100)\n",
        "print(f\"MRR@100: {mrr_score:.4f}\")\n",
        "\n",
        "# 4. Tune hyperparameters (uncomment to run - this takes time)\n",
        "# print(\"\\Tuning IALS hyperparameters...\")\n",
        "# best_params, best_mrr = tune_ials_hyperparameters(train_ratings, test_ratings)\n",
        "\n",
        "# 5. Train with optimal hyperparameters\n",
        "# You would normally use the best parameters from tuning\n",
        "optimal_k = 40  # Example value - use results from tuning\n",
        "optimal_lam = 0.1\n",
        "optimal_alpha = 40\n",
        "\n",
        "print(f\"\\\n",
        "Training IALS with optimal parameters (k={optimal_k}, λ={optimal_lam}, α={optimal_alpha})...\")\n",
        "user_embeddings_opt, item_embeddings_opt = ials(\n",
        "    train_ratings, k=optimal_k, lam=optimal_lam, alpha=optimal_alpha, n_iterations=15\n",
        ")\n",
        "\n",
        "# Calculate MRR with optimal model\n",
        "mrr_opt = mrr(user_embeddings_opt, item_embeddings_opt, test_ratings, train_ratings, k=100)\n",
        "print(f\"Optimal MRR@100: {mrr_opt:.4f}\")\n",
        "\n",
        "# 6. Compute item similarities using different methods\n",
        "print(\"\\\n",
        "Computing item similarities...\")\n",
        "\n",
        "# I2I Cosine similarity from collaborative filtering\n",
        "print(\"- Computing I2I Cosine similarity...\")\n",
        "i2i_cosine_sim = calculate_i2i_similarities(train_ratings, method='cosine', min_common=5)\n",
        "\n",
        "# I2I Jaccard similarity\n",
        "print(\"- Computing I2I Jaccard similarity...\")\n",
        "i2i_jaccard_sim = calculate_i2i_similarities(train_ratings, method='jaccard', min_common=5)\n",
        "\n",
        "# IALS-based similarity\n",
        "print(\"- Computing IALS-based similarity...\")\n",
        "ials_sim = get_ials_similarities(item_embeddings_opt)\n",
        "\n",
        "# 7. Compare similarities\n",
        "print(\"\\\n",
        "Comparing similarities between methods...\")\n",
        "similarities_list = [i2i_cosine_sim, i2i_jaccard_sim, ials_sim]\n",
        "method_names = ['I2I Cosine', 'I2I Jaccard', 'IALS']\n",
        "\n",
        "# Compare with item names for better interpretability\n",
        "compare_similarities(similarities_list, method_names, item_names=item_names, sample_size=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5544dc69",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-06T05:12:40.299803Z",
          "start_time": "2023-11-06T05:12:40.290403Z"
        },
        "id": "5544dc69"
      },
      "source": [
        "Conclusion:\n",
        "\n",
        "...."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "finalized": {
      "timestamp": 1686173501421,
      "trusted": false
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "302.398px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
